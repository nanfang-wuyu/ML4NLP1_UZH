{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nanfang-wuyu/ML4NLP1_UZH/blob/main/Assignment%202/word_embeddings_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Wvrt-REqt5ez"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "I8nRgRNyrJX5"
      },
      "outputs": [],
      "source": [
        "# Optional for word correction\n",
        "# %pip install textblob\n",
        "# %pip install pyspellchecker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMv2k-eFt5e5"
      },
      "source": [
        "Source: [https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html#exercise-computing-word-embeddings-continuous-bag-of-words](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html#exercise-computing-word-embeddings-continuous-bag-of-words)\n",
        "\n",
        "# Word Embeddings: Encoding Lexical Semantics\n",
        "\n",
        "Word embeddings are dense vectors of real numbers, one per word in your\n",
        "vocabulary. In NLP, it is almost always the case that your features are\n",
        "words! But how should you represent a word in a computer? You could\n",
        "store its ascii character representation, but that only tells you what\n",
        "the word *is*, it doesn't say much about what it *means* (you might be\n",
        "able to derive its part of speech from its affixes, or properties from\n",
        "its capitalization, but not much). Even more, in what sense could you\n",
        "combine these representations? We often want dense outputs from our\n",
        "neural networks, where the inputs are $|V|$ dimensional, where\n",
        "$V$ is our vocabulary, but often the outputs are only a few\n",
        "dimensional (if we are only predicting a handful of labels, for\n",
        "instance). How do we get from a massive dimensional space to a smaller\n",
        "dimensional space?\n",
        "\n",
        "How about instead of ascii representations, we use a one-hot encoding?\n",
        "That is, we represent the word $w$ by\n",
        "\n",
        "\\begin{align}\\overbrace{\\left[ 0, 0, \\dots, 1, \\dots, 0, 0 \\right]}^\\text{|V| elements}\\end{align}\n",
        "\n",
        "where the 1 is in a location unique to $w$. Any other word will\n",
        "have a 1 in some other location, and a 0 everywhere else.\n",
        "\n",
        "There is an enormous drawback to this representation, besides just how\n",
        "huge it is. It basically treats all words as independent entities with\n",
        "no relation to each other. What we really want is some notion of\n",
        "*similarity* between words. Why? Let's see an example.\n",
        "\n",
        "Suppose we are building a language model. Suppose we have seen the\n",
        "sentences\n",
        "\n",
        "* The mathematician ran to the store.\n",
        "* The physicist ran to the store.\n",
        "* The mathematician solved the open problem.\n",
        "\n",
        "in our training data. Now suppose we get a new sentence never before\n",
        "seen in our training data:\n",
        "\n",
        "* The physicist solved the open problem.\n",
        "\n",
        "Our language model might do OK on this sentence, but wouldn't it be much\n",
        "better if we could use the following two facts:\n",
        "\n",
        "* We have seen  mathematician and physicist in the same role in a sentence. Somehow they\n",
        "  have a semantic relation.\n",
        "* We have seen mathematician in the same role  in this new unseen sentence\n",
        "  as we are now seeing physicist.\n",
        "\n",
        "and then infer that physicist is actually a good fit in the new unseen\n",
        "sentence? This is what we mean by a notion of similarity: we mean\n",
        "*semantic similarity*, not simply having similar orthographic\n",
        "representations. It is a technique to combat the sparsity of linguistic\n",
        "data, by connecting the dots between what we have seen and what we\n",
        "haven't. This example of course relies on a fundamental linguistic\n",
        "assumption: that words appearing in similar contexts are related to each\n",
        "other semantically. This is called the `distributional\n",
        "hypothesis <https://en.wikipedia.org/wiki/Distributional_semantics>`__.\n",
        "\n",
        "\n",
        "# Getting Dense Word Embeddings\n",
        "\n",
        "How can we solve this problem? That is, how could we actually encode\n",
        "semantic similarity in words? Maybe we think up some semantic\n",
        "attributes. For example, we see that both mathematicians and physicists\n",
        "can run, so maybe we give these words a high score for the \"is able to\n",
        "run\" semantic attribute. Think of some other attributes, and imagine\n",
        "what you might score some common words on those attributes.\n",
        "\n",
        "If each attribute is a dimension, then we might give each word a vector,\n",
        "like this:\n",
        "\n",
        "\\begin{align}q_\\text{mathematician} = \\left[ \\overbrace{2.3}^\\text{can run},\n",
        "   \\overbrace{9.4}^\\text{likes coffee}, \\overbrace{-5.5}^\\text{majored in Physics}, \\dots \\right]\\end{align}\n",
        "\n",
        "\\begin{align}q_\\text{physicist} = \\left[ \\overbrace{2.5}^\\text{can run},\n",
        "   \\overbrace{9.1}^\\text{likes coffee}, \\overbrace{6.4}^\\text{majored in Physics}, \\dots \\right]\\end{align}\n",
        "\n",
        "Then we can get a measure of similarity between these words by doing:\n",
        "\n",
        "\\begin{align}\\text{Similarity}(\\text{physicist}, \\text{mathematician}) = q_\\text{physicist} \\cdot q_\\text{mathematician}\\end{align}\n",
        "\n",
        "Although it is more common to normalize by the lengths:\n",
        "\n",
        "\\begin{align}\\text{Similarity}(\\text{physicist}, \\text{mathematician}) = \\frac{q_\\text{physicist} \\cdot q_\\text{mathematician}}\n",
        "   {\\| q_\\text{\\physicist} \\| \\| q_\\text{mathematician} \\|} = \\cos (\\phi)\\end{align}\n",
        "\n",
        "Where $\\phi$ is the angle between the two vectors. That way,\n",
        "extremely similar words (words whose embeddings point in the same\n",
        "direction) will have similarity 1. Extremely dissimilar words should\n",
        "have similarity -1.\n",
        "\n",
        "\n",
        "You can think of the sparse one-hot vectors from the beginning of this\n",
        "section as a special case of these new vectors we have defined, where\n",
        "each word basically has similarity 0, and we gave each word some unique\n",
        "semantic attribute. These new vectors are *dense*, which is to say their\n",
        "entries are (typically) non-zero.\n",
        "\n",
        "But these new vectors are a big pain: you could think of thousands of\n",
        "different semantic attributes that might be relevant to determining\n",
        "similarity, and how on earth would you set the values of the different\n",
        "attributes? Central to the idea of deep learning is that the neural\n",
        "network learns representations of the features, rather than requiring\n",
        "the programmer to design them herself. So why not just let the word\n",
        "embeddings be parameters in our model, and then be updated during\n",
        "training? This is exactly what we will do. We will have some *latent\n",
        "semantic attributes* that the network can, in principle, learn. Note\n",
        "that the word embeddings will probably not be interpretable. That is,\n",
        "although with our hand-crafted vectors above we can see that\n",
        "mathematicians and physicists are similar in that they both like coffee,\n",
        "if we allow a neural network to learn the embeddings and see that both\n",
        "mathematicians and physicists have a large value in the second\n",
        "dimension, it is not clear what that means. They are similar in some\n",
        "latent semantic dimension, but this probably has no interpretation to\n",
        "us.\n",
        "\n",
        "\n",
        "In summary, **word embeddings are a representation of the *semantics* of\n",
        "a word, efficiently encoding semantic information that might be relevant\n",
        "to the task at hand**. You can embed other things too: part of speech\n",
        "tags, parse trees, anything! The idea of feature embeddings is central\n",
        "to the field.\n",
        "\n",
        "\n",
        "# Word Embeddings in Pytorch\n",
        "\n",
        "Before we get to a worked example and an exercise, a few quick notes\n",
        "about how to use embeddings in Pytorch and in deep learning programming\n",
        "in general. Similar to how we defined a unique index for each word when\n",
        "making one-hot vectors, we also need to define an index for each word\n",
        "when using embeddings. These will be keys into a lookup table. That is,\n",
        "embeddings are stored as a $|V| \\times D$ matrix, where $D$\n",
        "is the dimensionality of the embeddings, such that the word assigned\n",
        "index $i$ has its embedding stored in the $i$'th row of the\n",
        "matrix. In all of my code, the mapping from words to indices is a\n",
        "dictionary named word\\_to\\_ix.\n",
        "\n",
        "The module that allows you to use embeddings is torch.nn.Embedding,\n",
        "which takes two arguments: the vocabulary size, and the dimensionality\n",
        "of the embeddings.\n",
        "\n",
        "To index into this table, you must use torch.LongTensor (since the\n",
        "indices are integers, not floats).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELBc1ntbt5e8",
        "outputId": "6aa80f71-0452-4551-c201-e35626fe1b6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a48a89c7e90>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Author: Robert Guthrie\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcvzqik4t5e9",
        "outputId": "98abefee-f500-419a-e712-566ab2ec1bbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.6614,  0.2669,  0.0617,  0.6213, -0.4519]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ],
      "source": [
        "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
        "embeds = nn.Embedding(2, 5)  # 2 words in vocab, 5 dimensional embeddings # randomly initial\n",
        "lookup_tensor = torch.tensor([word_to_ix[\"hello\"]], dtype=torch.long)\n",
        "hello_embed = embeds(lookup_tensor)\n",
        "print(hello_embed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HnwjuilEj7I",
        "outputId": "edb86917-d846-4c74-de10-b98c56f99490"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1661, -1.5228,  0.3817, -1.0276, -0.5631]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "embeds(torch.LongTensor([1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es54fI4yt5e-"
      },
      "source": [
        "# An Example: N-Gram Language Modeling\n",
        "\n",
        "Recall that in an n-gram language model, given a sequence of words\n",
        "$w$, we want to compute\n",
        "\n",
        "\\begin{align}P(w_i | w_{i-1}, w_{i-2}, \\dots, w_{i-n+1} )\\end{align}\n",
        "\n",
        "Where $w_i$ is the ith word of the sequence.\n",
        "\n",
        "In this example, we will compute the loss function on some training\n",
        "examples and update the parameters with backpropagation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKEd73J5t5e_",
        "outputId": "ed5525ed-094b-4505-e1c3-81677182f7e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['When', 'forty'], 'winters'), (['forty', 'winters'], 'shall'), (['winters', 'shall'], 'besiege')]\n",
            "[523.4714274406433, 520.8815507888794, 518.309253692627, 515.754070520401, 513.2145917415619, 510.6909005641937, 508.1826972961426, 505.6879105567932, 503.2051067352295, 500.7331578731537]\n"
          ]
        }
      ],
      "source": [
        "CONTEXT_SIZE = 2\n",
        "EMBEDDING_DIM = 10\n",
        "# We will use Shakespeare Sonnet 2\n",
        "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
        "And dig deep trenches in thy beauty's field,\n",
        "Thy youth's proud livery so gazed on now,\n",
        "Will be a totter'd weed of small worth held:\n",
        "Then being asked, where all thy beauty lies,\n",
        "Where all the treasure of thy lusty days;\n",
        "To say, within thine own deep sunken eyes,\n",
        "Were an all-eating shame, and thriftless praise.\n",
        "How much more praise deserv'd thy beauty's use,\n",
        "If thou couldst answer 'This fair child of mine\n",
        "Shall sum my count, and make my old excuse,'\n",
        "Proving his beauty by succession thine!\n",
        "This were to be new made when thou art old,\n",
        "And see thy blood warm when thou feel'st it cold.\"\"\".split()\n",
        "# we should tokenize the input, but we will ignore that for now\n",
        "# build a list of tuples.  Each tuple is ([ word_i-2, word_i-1 ], target word)\n",
        "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
        "            for i in range(len(test_sentence) - 2)]\n",
        "# print the first 3, just so you can see what they look like\n",
        "print(trigrams[:3])\n",
        "\n",
        "vocab = set(test_sentence)\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "\n",
        "class NGramLanguageModeler(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "        super(NGramLanguageModeler, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
        "        self.linear2 = nn.Linear(128, vocab_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs).view((1, -1))\n",
        "        out = F.relu(self.linear1(embeds))\n",
        "        out = self.linear2(out)\n",
        "        log_probs = F.log_softmax(out, dim=1)\n",
        "        return log_probs\n",
        "\n",
        "\n",
        "losses = []\n",
        "loss_function = nn.NLLLoss()\n",
        "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    total_loss = 0\n",
        "    for context, target in trigrams:\n",
        "\n",
        "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
        "        # into integer indices and wrap them in tensors)\n",
        "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
        "\n",
        "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
        "        # new instance, you need to zero out the gradients from the old\n",
        "        # instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 3. Run the forward pass, getting log probabilities over next\n",
        "        # words\n",
        "        log_probs = model(context_idxs)\n",
        "\n",
        "        # n probs, 1 target idx\n",
        "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
        "        # word wrapped in a tensor)\n",
        "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
        "\n",
        "        # Step 5. Do the backward pass and update the gradient\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
        "        total_loss += loss.item()\n",
        "    losses.append(total_loss)\n",
        "print(losses)  # The loss decreased every iteration over the training data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO-_4P3mt5e_"
      },
      "source": [
        "# Exercise: Computing Word Embeddings: Continuous Bag-of-Words\n",
        "\n",
        "The Continuous Bag-of-Words model (CBOW) is frequently used in NLP deep\n",
        "learning. It is a model that tries to predict words given the context of\n",
        "a few words before and a few words after the target word. This is\n",
        "distinct from language modeling, since CBOW is not sequential and does\n",
        "not have to be probabilistic. Typcially, CBOW is used to quickly train\n",
        "word embeddings, and these embeddings are used to initialize the\n",
        "embeddings of some more complicated model. Usually, this is referred to\n",
        "as *pretraining embeddings*. It almost always helps performance a couple\n",
        "of percent.\n",
        "\n",
        "The CBOW model is as follows. Given a target word $w_i$ and an\n",
        "$N$ context window on each side, $w_{i-1}, \\dots, w_{i-N}$\n",
        "and $w_{i+1}, \\dots, w_{i+N}$, referring to all context words\n",
        "collectively as $C$, CBOW tries to minimize\n",
        "\n",
        "\\begin{align}-\\log p(w_i | C) = -\\log \\text{Softmax}(A(\\sum_{w \\in C} q_w) + b)\\end{align}\n",
        "\n",
        "where $q_w$ is the embedding for word $w$.\n",
        "\n",
        "Implement this model in Pytorch by filling in the class below. Some\n",
        "tips:\n",
        "\n",
        "* Think about which parameters you need to define.\n",
        "* Make sure you know what shape each operation expects. Use .view() if you need to\n",
        "  reshape.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXbt-utMt5fA",
        "outputId": "a6f7f8c9-a516-4ff9-aee3-aed0e3aa31c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['We', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'a'], 'idea')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([33, 41, 46, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
        "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
        "Computational processes are abstract beings that inhabit computers.\n",
        "As they evolve, processes manipulate other abstract things called data.\n",
        "The evolution of a process is directed by a pattern of rules\n",
        "called a program. People create programs to direct processes. In effect,\n",
        "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
        "\n",
        "# By deriving a set from `raw_text`, we deduplicate the array\n",
        "vocab = set(raw_text)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "data = []\n",
        "for i in range(2, len(raw_text) - 2):\n",
        "    context = [raw_text[i - 2], raw_text[i - 1],\n",
        "               raw_text[i + 1], raw_text[i + 2]]\n",
        "    target = raw_text[i]\n",
        "    data.append((context, target))\n",
        "print(data[:5])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def make_context_vector(context, word_to_ix):\n",
        "    idxs = [word_to_ix[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "# data[i]: i-th contexts-target pair\n",
        "# data[i][0]: 4 contexts (list)\n",
        "# data[i][1]: target (text)\n",
        "make_context_vector(data[0][0], word_to_ix)  # example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z7Wt1QTEj7J"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOW(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "        super(CBOW, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    \"\"\"\n",
        "    Since the objective is to learn embeddings,\n",
        "    instead of prediction or classification tasks,\n",
        "    there is no need to add softmax layer.\n",
        "    \"\"\"\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs)\n",
        "        embeds = torch.sum(embeds, dim=1)\n",
        "        out = self.linear(embeds)\n",
        "        return out\n",
        "\n",
        "# create your model and train.  here are some functions to help you make\n",
        "# the data ready for use by your module\n"
      ],
      "metadata": {
        "id": "EhHtT-Jb0kP4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpQoX18vEj7K"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7Qypj6GrJYA",
        "outputId": "27a21f48-6add-4fc9-ff86-11636b3e5867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1foE1JuZJeu5E_4qVge9kExzhvF32teuF\n",
            "To: /content/tripadvisor_hotel_reviews_reduced.csv\n",
            "100% 7.36M/7.36M [00:00<00:00, 111MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13IWXrTjGTrfCd9l7dScZVO8ZvMicPU75\n",
            "To: /content/scifi_reduced.txt\n",
            "100% 43.1M/43.1M [00:00<00:00, 169MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1foE1JuZJeu5E_4qVge9kExzhvF32teuF\n",
        "!gdown 13IWXrTjGTrfCd9l7dScZVO8ZvMicPU75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "imtLiRo4Ej7K"
      },
      "outputs": [],
      "source": [
        "with open(f'scifi_reduced.txt') as f:\n",
        "    text_scifi = f.read()\n",
        "import pandas as pd\n",
        "df_hotel = pd.read_csv('tripadvisor_hotel_reviews_reduced.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "biyGDhsMEj7K",
        "outputId": "9627c980-198b-4064-85b6-bac498ddd0e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' A chat with the edi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "text_scifi[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YbfJbJmdEj7K",
        "outputId": "527b00ba-6ff5-4b15-ab06-1ba3c9b5e411"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Review  Rating\n",
              "0  fantastic service large hotel caters business ...       5\n",
              "1  great hotel modern hotel good location, locate...       4\n",
              "2  3 star plus glasgowjust got 30th november 4 da...       4\n",
              "3  nice stayed hotel nov 19-23. great little bout...       4\n",
              "4  great place wonderful hotel ideally located me...       5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17f25014-1518-4c86-bf71-910366790ea7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fantastic service large hotel caters business ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>great hotel modern hotel good location, locate...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3 star plus glasgowjust got 30th november 4 da...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nice stayed hotel nov 19-23. great little bout...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great place wonderful hotel ideally located me...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17f25014-1518-4c86-bf71-910366790ea7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17f25014-1518-4c86-bf71-910366790ea7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17f25014-1518-4c86-bf71-910366790ea7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d6d09bc4-c27b-457f-96cf-d7468206ca9b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6d09bc4-c27b-457f-96cf-d7468206ca9b')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d6d09bc4-c27b-457f-96cf-d7468206ca9b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "df_hotel[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "XgKXf2cIEj7K"
      },
      "outputs": [],
      "source": [
        "text_hotel = df_hotel.drop(columns=[\"Rating\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Cq4T39VpEj7K",
        "outputId": "702624c2-cd22-448f-9e5b-6a5a256c915e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Review\n",
              "0  fantastic service large hotel caters business ...\n",
              "1  great hotel modern hotel good location, locate...\n",
              "2  3 star plus glasgowjust got 30th november 4 da...\n",
              "3  nice stayed hotel nov 19-23. great little bout...\n",
              "4  great place wonderful hotel ideally located me..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d25ea68-67e9-4e6d-83c4-83d5b11b281b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fantastic service large hotel caters business ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>great hotel modern hotel good location, locate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3 star plus glasgowjust got 30th november 4 da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nice stayed hotel nov 19-23. great little bout...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great place wonderful hotel ideally located me...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d25ea68-67e9-4e6d-83c4-83d5b11b281b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3d25ea68-67e9-4e6d-83c4-83d5b11b281b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3d25ea68-67e9-4e6d-83c4-83d5b11b281b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a919ce51-bff2-495a-9576-f6abb24d6f9e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a919ce51-bff2-495a-9576-f6abb24d6f9e')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a919ce51-bff2-495a-9576-f6abb24d6f9e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "text_hotel[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXPIBA6hrJX_"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4hG6-b7Ej7K"
      },
      "source": [
        "<!-- 1. Data Cleaning, 2. **Character Casing**, 3. **Splitting Sentences** (optional), 4. **Tokenizing Words**, 5. **Dealing with Punctuation**, 6. Expanding Contractions (optional), 7. **Removing Stopwords**, 8. Lemmatization and Stemming (optional), 9. Handling Special Cases, 10. Handling Rare Words and Out-of-Vocabulary Words.\n",
        " -->\n",
        "\n",
        "\n",
        "1. Special Characters Cleaning\n",
        "2. Character Casing\n",
        "3. Tokenizing Words\n",
        "4. Stop Word Removal\n",
        "5. Stemming\n",
        "6. Handling Rare Words and Out-of-Vocabulary Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "z4w_OARNrJYA"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "7XqQ_dU1rJYA"
      },
      "outputs": [],
      "source": [
        "# Brief text to test pre-processing functions\n",
        "text = \"It's a text to test pre-processing functions (a tstword). This is a repeat: It's a text to test pre-processing functions (a tstword).\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRuoVyw_rJYA"
      },
      "source": [
        "### Special Characters Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "X0ShvmYtrJYA"
      },
      "outputs": [],
      "source": [
        "# import library: Regular Expression\n",
        "import re\n",
        "\n",
        "\"\"\"\n",
        "Clean the data by removing special characters (punctuation)\n",
        "\"\"\"\n",
        "def sp_chara_cleaning(text):\n",
        "    clean_text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
        "    return clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfxbIsCprJYA",
        "outputId": "043d8cbf-5902-439e-fb18-42c23de55c0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['trap', 'music', '123', 'gmail', 'How', 'are', 'you']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Test it\n",
        "sp_chara_cleaning(\"#trap music <123> @gmail! How are you?\")\n",
        "' trap music  123   gmail  How are you '.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "WlUVw3LNrJYB",
        "outputId": "c61f2656-f24b-4ad6-df8f-7e82bea3d59d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'It s a text to test pre processing functions  a tstword   This is a repeat  It s a text to test pre processing functions  a tstword  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Special characters like ' . - are removed.\n",
        "text = sp_chara_cleaning(text)\n",
        "text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xo4BowqMrJYB"
      },
      "source": [
        "### Character Casing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "U2Cu7hFcrJYB"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Lowercase all words.\n",
        "\"\"\"\n",
        "def character_casing(text):\n",
        "    lower_text = text.lower()\n",
        "    return lower_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "P6B_BBNtrJYB",
        "outputId": "07665614-8894-4b21-93ef-8a6bb115cc1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'it s a text to test pre processing functions  a tstword   this is a repeat  it s a text to test pre processing functions  a tstword  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# All cases become lowercases.\n",
        "text = character_casing(text)\n",
        "text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8deaEdJrJYB"
      },
      "source": [
        "### Tokenizing Words"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNIh3VWSr_MI",
        "outputId": "fa415e09-0033-4b76-e04b-d3bf8bca2896"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "JAyb9QRlrJYB"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\"\"\"Tokenize the text to words for further data processing functions.\"\"\"\n",
        "def tokenize_words(text):\n",
        "    return word_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMetRaPWrJYB",
        "outputId": "6bfd8d6f-5808-4ad9-b15a-a33f3e286f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['it', 's', 'a', 'text', 'to', 'test', 'pre', 'processing', 'functions', 'a', 'tstword', 'this', 'is', 'a', 'repeat', 'it', 's', 'a', 'text', 'to', 'test', 'pre', 'processing', 'functions', 'a', 'tstword']\n"
          ]
        }
      ],
      "source": [
        "words = tokenize_words(text)\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djt89UgKrJYB"
      },
      "source": [
        "### Stop Word Removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0divjiW-rJYB",
        "outputId": "f5c82116-e5ef-4667-9a09-1e9a340b1262"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "S4Um6fd3rJYC"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "\"\"\"\n",
        "Here we remove words that in English stop words list.\n",
        "\"\"\"\n",
        "def stop_word_removal(words):\n",
        "    stop_words = stopwords.words(\"english\")\n",
        "    clean_words = [w for w in words if w not in stop_words]\n",
        "    return clean_words\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsLUAziDrJYC",
        "outputId": "52baf42a-14fe-468f-a832-ace526faff0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['text', 'test', 'pre', 'processing', 'functions', 'tstword', 'repeat', 'text', 'test', 'pre', 'processing', 'functions', 'tstword']\n"
          ]
        }
      ],
      "source": [
        "# Stop words like 'it', 's', 'a', 'this' are removed.\n",
        "words = stop_word_removal(words)\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb8L7KqJrJYC"
      },
      "source": [
        "### Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "r-tapET-rJYQ"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Here we do stemming for the text, which reduces words to their root form.\n",
        "We choose PorterStemmer, which is a helpful algorithm.\n",
        "\"\"\"\n",
        "def stemming(words):\n",
        "    stemmer = PorterStemmer()\n",
        "    clean_words = [stemmer.stem(w) for w in words]\n",
        "    return clean_words\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemming([\"guests\", \"takes\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKiUW-p3xEje",
        "outputId": "46e74505-fff1-4b59-f260-dc9346b26678"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['guest', 'take']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO-HIlB4rJYQ",
        "outputId": "e24bff7a-298a-422c-9e84-31b167152f2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['text', 'test', 'pre', 'process', 'function', 'tstword', 'repeat', 'text', 'test', 'pre', 'process', 'function', 'tstword']\n"
          ]
        }
      ],
      "source": [
        "# Here 'testing' is reduced to 'test', 'functions' is reduced to 'function'.\n",
        "words = stemming(words)\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwXbo2WVrJYR"
      },
      "source": [
        "### Handling Rare Words and Out-of-Vocabulary Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA_bPyVtrJYR",
        "outputId": "dcce67bb-6ce1-43a2-dfa3-7c0862061497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "sWGZNAPwrJYR"
      },
      "outputs": [],
      "source": [
        "from nltk import FreqDist\n",
        "\n",
        "\"\"\"\n",
        "Here we handle rare words and out of vocabulary (OOV) words.\n",
        "We use FreqDist to calculate frequences of all words.\n",
        "We use nltk.corpus.words.words() as our vocabulary to handle OOV.\n",
        "We choose words over minimum frequence and in vocabulary.\n",
        "Since handling OOV words cost much time, we set it default to False,\n",
        "which will be more convenient for peer reviewers.\n",
        "\"\"\"\n",
        "def handle_rare_and_OOV(words, min_freq=10, handle_oov=False):\n",
        "    vocab = nltk.corpus.words.words()\n",
        "    word_freq = FreqDist(words)\n",
        "    if handle_oov:\n",
        "        clean_words = [w for w in words if word_freq[w] >= min_freq and w in vocab]\n",
        "    else:\n",
        "        clean_words = [w for w in words if word_freq[w] >= min_freq]\n",
        "    return clean_words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W01-fMWYrJYR",
        "outputId": "1bbac074-7449-4823-f225-ab2d32b05cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['text', 'test', 'pre', 'process', 'function', 'tstword', 'text', 'test', 'pre', 'process', 'function', 'tstword']\n"
          ]
        }
      ],
      "source": [
        "# Here rare word 'pre' and OOV word 'tstword' are removed\n",
        "words = handle_rare_and_OOV(words, 2)\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTMuVDEaEj7L"
      },
      "source": [
        "### Apply Preprocessing Functions\n",
        "Skip this if you already have saved data after pre-processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxdCMwI9rJYR"
      },
      "source": [
        "#### Hotel Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "wl5BxRFXEj7L",
        "outputId": "a8fd17ff-82e0-4e46-db84-ad9d6dfa97e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fantastic service large hotel caters business corporates, serve provided better wife experienced- nothing short world.the room upgraded superior room overlooking harbour marina large window 50 feet length, anniversary bottle champagne sent chocolates compliments management, expensive did not regret moment choice hotel, highly recommended exclusive hotel break pamper,  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# show text before preprocessing\n",
        "text_hotel[\"Review\"].iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UINN_9g9Ej7L",
        "outputId": "a658b217-e9f8-4a10-8cd3-c8eff17c8e21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sp_chara_cleaning\n",
            "character_casing\n",
            "tokenize_words\n",
            "stop_word_removal\n",
            "stemming\n",
            "handle_rare_and_OOV\n"
          ]
        }
      ],
      "source": [
        "funcs = [sp_chara_cleaning, character_casing, tokenize_words, stop_word_removal, stemming, handle_rare_and_OOV]\n",
        "\n",
        "full_text_hotel = ' '.join(text_hotel['Review'])\n",
        "words_hotel = full_text_hotel\n",
        "for i, func in enumerate(funcs):\n",
        "    print(func.__name__)\n",
        "    words_hotel = func(words_hotel)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ey1_92k5Ej7L",
        "outputId": "195fe9ca-ce2c-4a25-e5e1-0cff755ae96b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'fantast hotel cater better wife short world room superior room overlook harbour marina window length sent compliment regret moment hotel'"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# show text after preprocessing\n",
        "\" \".join(words_hotel[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "id": "4n7OdSAzrJYS"
      },
      "outputs": [],
      "source": [
        "with open('clean_hotel.txt', 'w') as file:\n",
        "    file.write(' '.join(words_hotel))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmEJGq4JrJYS"
      },
      "source": [
        "#### Scifi Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uYgiDdaXEj7L",
        "outputId": "dfbafb31-d65c-4914-ed9a-165855cc5233"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' A chat with the editor  i #  science fiction magazine calle'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# show text before preprocessing\n",
        "text_scifi[:60]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CS92wEGNEj7M",
        "outputId": "7da82c65-00e6-4fa4-805e-a986251a8d8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sp_chara_cleaning\n",
            "character_casing\n",
            "tokenize_words\n",
            "stop_word_removal\n",
            "stemming\n",
            "handle_rare_and_OOV\n"
          ]
        }
      ],
      "source": [
        "funcs = [sp_chara_cleaning, character_casing, tokenize_words, stop_word_removal, stemming, handle_rare_and_OOV]\n",
        "\n",
        "words_scifi = text_scifi\n",
        "for i, func in enumerate(funcs):\n",
        "    print(func.__name__)\n",
        "    words_scifi = func(words_scifi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvzRoHnvrJYS",
        "outputId": "f42f7ecd-4588-4948-b782-275fb8547831"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'chat editor scienc fiction magazin call titl select much thought breviti theori indic field easi rememb tent titl morn rememb'"
            ]
          },
          "execution_count": 201,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# show text after preprocessing\n",
        "\" \".join(words_scifi[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "kDxl9jsCrJYT"
      },
      "outputs": [],
      "source": [
        "with open('clean_scifi.txt', 'w') as file:\n",
        "    file.write(' '.join(words_scifi))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3AwotczEj7M"
      },
      "source": [
        "### Create Dataset For Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "wyc3_NN7rJYT"
      },
      "outputs": [],
      "source": [
        "# Load dataset after cleaning. If you have done data pre-processing in the same\n",
        "# kernel process, you can skip it.\n",
        "with open('clean_hotel.txt', 'r') as file:\n",
        "    words_hotel = file.read().split(' ')\n",
        "with open('clean_scifi.txt', 'r') as file:\n",
        "    words_scifi = file.read().split(' ')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "rmJcysCNVqHd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Save indexs of targets to i_target_tensor, indexs of context list to i_context_tensor.\n",
        "\"\"\"\n",
        "def create_triagrams(i_text, context_size=2):\n",
        "    i_context_tensor = []\n",
        "    i_target_tensor = []\n",
        "    for i in range(context_size, len(i_text) - context_size):\n",
        "        i_contexts = [i_text[j] for j in range(i - context_size, i + context_size + 1) if i != j]\n",
        "        i_target = i_text[i]\n",
        "        i_context_tensor.append(i_contexts)\n",
        "        i_target_tensor.append(i_target)\n",
        "    i_target_tensor = torch.LongTensor(i_target_tensor)\n",
        "    i_context_tensor = torch.LongTensor(i_context_tensor)\n",
        "    return i_context_tensor, i_target_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp-USTHqVqHd"
      },
      "source": [
        "#### SCIFI DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "KsQL8PjKEj7M"
      },
      "outputs": [],
      "source": [
        "vocab_scifi = list(set(words_scifi))\n",
        "word_to_ix_scifi = {word: i for i, word in enumerate(vocab_scifi)}\n",
        "i_text_scifi = [word_to_ix_scifi[w] for w in words_scifi]\n",
        "i_context_scifi, i_target_scifi = create_triagrams(i_text_scifi, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIJAH-o9VqHe",
        "outputId": "556be1ee-08d1-4341-c58e-5759090df14c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3770291, 16754, torch.Size([3770287]), torch.Size([3770287, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "len(words_scifi), len(vocab_scifi), i_target_scifi.shape, i_context_scifi.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVLk_q4HVqHe"
      },
      "source": [
        "#### HOTEL DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "FDq4LCBHEj7M"
      },
      "outputs": [],
      "source": [
        "vocab_hotel = list(set(words_hotel))\n",
        "word_to_ix_hotel = {word: i for i, word in enumerate(vocab_hotel)}\n",
        "i_text_hotel = [word_to_ix_hotel[w] for w in words_hotel]\n",
        "i_context_hotel_2, i_target_hotel_2 = create_triagrams(i_text_hotel, 2)\n",
        "i_context_hotel_5, i_target_hotel_5 = create_triagrams(i_text_hotel, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS3bUH_IrJYT",
        "outputId": "e0e2c2c7-544d-445e-ffc3-5b07935378a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(708517, 2776)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "len(words_hotel), len(vocab_hotel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ipR674_VqHe",
        "outputId": "793c4f48-c3b2-423c-8c52-f7a0e087f417"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([708513, 4]),\n",
              " torch.Size([708513]),\n",
              " torch.Size([708507, 10]),\n",
              " torch.Size([708507]))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "i_context_hotel_2.shape, i_target_hotel_2.shape, i_context_hotel_5.shape, i_target_hotel_5.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhUXY0u0Ej7M"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "eNWVkL4sEj7M"
      },
      "outputs": [],
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "# device = torch.device(\"mps\")\n",
        "# device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gk9fkwHG3du",
        "outputId": "ed0826f0-c6dd-49c7-cb4d-fbf4d22950d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "g6Y-IbSLW22q"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Ic1RjFd0ldAX"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "\n",
        "# Example from 05_intro_to_PyTorch.ipynb\n",
        "class MyDataset(IterableDataset):\n",
        "    def __init__(self, data_X, data_y):\n",
        "        assert len(data_X) == len(data_y)\n",
        "        self.data_X = data_X.to(device)\n",
        "        self.data_y = data_y.to(device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_X)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for i in range(len(self.data_X)):\n",
        "            yield (self.data_X[i], self.data_y[i])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "I7L4F4Pam0Lw"
      },
      "outputs": [],
      "source": [
        "def createDataLoader(X, y):\n",
        "  torch.manual_seed(1)\n",
        "  train_set = MyDataset(X, y)\n",
        "  train_loader = DataLoader(train_set, batch_size=64)\n",
        "  return train_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92e_HU7WEj7N"
      },
      "source": [
        "### CBOW 2 with Hotel Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "id": "qMORjhC9lxb9"
      },
      "outputs": [],
      "source": [
        "# Setting logging, dataloader, hyperparams, loss function and optimizer.\n",
        "logging.basicConfig(filename='training_hotel2.log', level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "train_loader = createDataLoader(i_context_hotel_2, i_target_hotel_2)\n",
        "CONTEXT_SIZE = 2\n",
        "EMBEDDING_DIM = 50\n",
        "losses = []\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "CBOW2_hotel_model = CBOW(len(vocab_hotel), EMBEDDING_DIM, CONTEXT_SIZE).to(device)\n",
        "optimizer = optim.SGD(CBOW2_hotel_model.parameters(), lr=0.1)\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "corfuBCLEj7N",
        "outputId": "7d7ba3b1-d7cb-4e3a-ea8b-0cd8a92fea04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 / 20 Loss: 6.5569 Time: 15.84s\n",
            "Epoch: 2 / 20 Loss: 6.1161 Time: 17.06s\n",
            "Epoch: 3 / 20 Loss: 6.0217 Time: 16.70s\n",
            "Epoch: 4 / 20 Loss: 5.9646 Time: 18.62s\n",
            "Epoch: 5 / 20 Loss: 5.9233 Time: 16.64s\n",
            "Epoch: 6 / 20 Loss: 5.8908 Time: 16.02s\n",
            "Epoch: 7 / 20 Loss: 5.8641 Time: 16.44s\n",
            "Epoch: 8 / 20 Loss: 5.8414 Time: 16.02s\n",
            "Epoch: 9 / 20 Loss: 5.8216 Time: 15.88s\n",
            "Epoch: 10 / 20 Loss: 5.8040 Time: 16.56s\n",
            "Epoch: 11 / 20 Loss: 5.7882 Time: 19.43s\n",
            "Epoch: 12 / 20 Loss: 5.7739 Time: 16.31s\n",
            "Epoch: 13 / 20 Loss: 5.7607 Time: 16.02s\n",
            "Epoch: 14 / 20 Loss: 5.7486 Time: 15.77s\n",
            "Epoch: 15 / 20 Loss: 5.7373 Time: 15.95s\n",
            "Epoch: 16 / 20 Loss: 5.7267 Time: 16.46s\n",
            "Epoch: 17 / 20 Loss: 5.7168 Time: 18.79s\n",
            "Epoch: 18 / 20 Loss: 5.7074 Time: 16.69s\n",
            "Epoch: 19 / 20 Loss: 5.6986 Time: 15.91s\n",
            "Epoch: 20 / 20 Loss: 5.6902 Time: 15.92s\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    start_time = time.time()\n",
        "    for batch_num, (i_context, i_target) in enumerate(train_loader):\n",
        "        # Torch accumulates gradients. Before passing in a\n",
        "        # new instance, zero out the gradients from the old instance\n",
        "        CBOW2_hotel_model.zero_grad()\n",
        "\n",
        "        # Run the forward pass, getting log probabilities over next words\n",
        "        log_probs = CBOW2_hotel_model(i_context)\n",
        "\n",
        "        # Compute loss function.\n",
        "        loss = loss_function(log_probs, i_target)\n",
        "\n",
        "        # Do the backward pass and update the gradient\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
        "    info = f\"Epoch: {epoch + 1} / {epochs} Loss: {total_loss / len(train_loader):.4f} \\\n",
        "Time: {time.time() - start_time:.2f}s\"\n",
        "    print(info)\n",
        "    logging.info(info)\n",
        "torch.save(CBOW2_hotel_model.state_dict(), f'CBOW2_hotel_model_{epochs}.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzeWf-8OYx8q"
      },
      "source": [
        "### CBOW 5 with Hotel Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "id": "jJc2k0cJtoMF"
      },
      "outputs": [],
      "source": [
        "# Setting logging, dataloader, hyperparams, loss function and optimizer.\n",
        "logging.basicConfig(filename='training_hotel5.log', level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "train_loader = createDataLoader(i_context_hotel_5, i_target_hotel_5)\n",
        "CONTEXT_SIZE = 5\n",
        "EMBEDDING_DIM = 50\n",
        "losses = []\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "CBOW5_hotel_model = CBOW(len(vocab_hotel), EMBEDDING_DIM, CONTEXT_SIZE).to(device)\n",
        "optimizer = optim.SGD(CBOW5_hotel_model.parameters(), lr=0.1)\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tyoJu9yYvwM",
        "outputId": "eea22c02-4145-4a4b-e1db-84297752735e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 / 20 Loss: 6.6255 Time: 16.82s\n",
            "Epoch: 2 / 20 Loss: 6.2512 Time: 16.79s\n",
            "Epoch: 3 / 20 Loss: 6.1686 Time: 18.01s\n",
            "Epoch: 4 / 20 Loss: 6.1169 Time: 16.79s\n",
            "Epoch: 5 / 20 Loss: 6.0788 Time: 20.59s\n",
            "Epoch: 6 / 20 Loss: 6.0484 Time: 21.54s\n",
            "Epoch: 7 / 20 Loss: 6.0230 Time: 23.22s\n",
            "Epoch: 8 / 20 Loss: 6.0010 Time: 17.90s\n",
            "Epoch: 9 / 20 Loss: 5.9816 Time: 17.96s\n",
            "Epoch: 10 / 20 Loss: 5.9642 Time: 18.78s\n",
            "Epoch: 11 / 20 Loss: 5.9484 Time: 17.31s\n",
            "Epoch: 12 / 20 Loss: 5.9339 Time: 20.03s\n",
            "Epoch: 13 / 20 Loss: 5.9205 Time: 18.92s\n",
            "Epoch: 14 / 20 Loss: 5.9080 Time: 16.17s\n",
            "Epoch: 15 / 20 Loss: 5.8964 Time: 16.77s\n",
            "Epoch: 16 / 20 Loss: 5.8854 Time: 16.57s\n",
            "Epoch: 17 / 20 Loss: 5.8751 Time: 16.00s\n",
            "Epoch: 18 / 20 Loss: 5.8653 Time: 22.79s\n",
            "Epoch: 19 / 20 Loss: 5.8561 Time: 18.57s\n",
            "Epoch: 20 / 20 Loss: 5.8473 Time: 18.58s\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    start_time = time.time()\n",
        "    for batch_num, (i_context, i_target) in enumerate(train_loader):\n",
        "\n",
        "        # Torch accumulates gradients. Before passing in a\n",
        "        # new instance, zero out the gradients from the old instance\n",
        "        CBOW5_hotel_model.zero_grad()\n",
        "\n",
        "        # Run the forward pass, getting log probabilities over next words\n",
        "        log_probs = CBOW5_hotel_model(i_context)\n",
        "\n",
        "        # Compute loss function.\n",
        "        loss = loss_function(log_probs, i_target)\n",
        "\n",
        "        # Do the backward pass and update the gradient\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    info = f\"Epoch: {epoch + 1} / {epochs} Loss: {total_loss / len(train_loader):.4f} \\\n",
        "Time: {time.time() - start_time:.2f}s\"\n",
        "    print(info)\n",
        "    logging.info(info)\n",
        "#     losses.append(total_loss)\n",
        "# print(losses)  # The loss decreased every iteration over the training data!\n",
        "torch.save(CBOW5_hotel_model.state_dict(), 'CBOW5_hotel_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLVLqs2fEj7O"
      },
      "source": [
        "### CBOW 2 with Scifi Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "id": "Qvtm42EKud07"
      },
      "outputs": [],
      "source": [
        "# Setting logging, dataloader, hyperparams, loss function and optimizer.\n",
        "logging.basicConfig(filename='training_scifi.log', level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "train_loader = createDataLoader(i_context_scifi, i_target_scifi)\n",
        "CONTEXT_SIZE = 2\n",
        "EMBEDDING_DIM = 50\n",
        "losses = []\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "CBOW2_scifi_model = CBOW(len(vocab_scifi), EMBEDDING_DIM, CONTEXT_SIZE).to(device)\n",
        "optimizer = optim.SGD(CBOW2_scifi_model.parameters(), lr=0.1)\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7v6jND-Ej7O",
        "outputId": "3db3357b-a96b-47a6-810c-343f45e2905e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 / 10 Loss: 8.4294 Time: 88.90s\n",
            "Epoch: 2 / 10 Loss: 7.9138 Time: 89.89s\n",
            "Epoch: 3 / 10 Loss: 7.8121 Time: 90.43s\n",
            "Epoch: 4 / 10 Loss: 7.7514 Time: 91.18s\n",
            "Epoch: 5 / 10 Loss: 7.7072 Time: 91.25s\n",
            "Epoch: 6 / 10 Loss: 7.6721 Time: 95.86s\n",
            "Epoch: 7 / 10 Loss: 7.6428 Time: 89.50s\n",
            "Epoch: 8 / 10 Loss: 7.6177 Time: 89.75s\n",
            "Epoch: 9 / 10 Loss: 7.5958 Time: 99.98s\n",
            "Epoch: 10 / 10 Loss: 7.5763 Time: 101.23s\n",
            "[496584.8132376671, 466208.168926239, 460217.6973621845, 456644.96947336197, 454040.4538923502, 451970.48763239384, 450246.8695342541, 448769.1400618553, 447476.03984856606, 446326.8780350685]\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    start_time = time.time()\n",
        "    for batch_num, (i_context, i_target) in enumerate(train_loader):\n",
        "\n",
        "        # Torch accumulates gradients. Before passing in a\n",
        "        # new instance, zero out the gradients from the old instance\n",
        "        CBOW2_scifi_model.zero_grad()\n",
        "\n",
        "        # Run the forward pass, getting log probabilities over next words\n",
        "        log_probs = CBOW2_scifi_model(i_context)\n",
        "\n",
        "        # Compute loss function.\n",
        "        loss = loss_function(log_probs, i_target)\n",
        "\n",
        "        # Do the backward pass and update the gradient\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
        "    info = f\"Epoch: {epoch + 1} / {epochs} Loss: {total_loss / len(train_loader):.4f} \\\n",
        "Time: {time.time() - start_time:.2f}s\"\n",
        "    print(info)\n",
        "    logging.info(info)\n",
        "    losses.append(total_loss)\n",
        "print(losses)  # The loss decreased every iteration over the training data!\n",
        "torch.save(CBOW2_scifi_model.state_dict(), 'CBOW2_scifi_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njZlt0pRrJYX"
      },
      "source": [
        "# Part 2 Embeddings Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eikncB-rJYX",
        "outputId": "5e4b402c-7583-4847-d476-80322cdaac3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CBOW(\n",
              "  (embeddings): Embedding(2776, 50)\n",
              "  (linear): Linear(in_features=50, out_features=2776, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "# Run here only if you load the model from directory.\n",
        "# If you have a model trained in this jupyter notebook kernel, move ahead.\n",
        "\n",
        "# CBOW2_hotel_model = CBOW(len(vocab_hotel), 50, 2).to(device)\n",
        "# CBOW2_hotel_model.load_state_dict(torch.load('CBOW2_hotel_model_20.pth', map_location=torch.device('cuda')))\n",
        "# CBOW2_hotel_model.eval()\n",
        "\n",
        "CBOW5_hotel_model = CBOW(len(vocab_hotel), 50, 5).to(device)\n",
        "CBOW5_hotel_model.load_state_dict(torch.load('CBOW5_hotel_model.pth', map_location=torch.device('cuda')))\n",
        "CBOW5_hotel_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Moie2LIwrJYX"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def get_closest_word(word, net, word_to_index, vocabulary, topn=5, device=device):\n",
        "    net.eval()\n",
        "    word_distance = []\n",
        "    emb = net.embeddings\n",
        "    pdist = nn.PairwiseDistance()\n",
        "    i = word_to_index[word]\n",
        "    lookup_tensor_i = torch.tensor([i], dtype=torch.long).to(device)\n",
        "    v_i = emb(lookup_tensor_i)\n",
        "    for j in range(len(vocabulary)):\n",
        "        if j != i:\n",
        "            lookup_tensor_j = torch.tensor([j], dtype=torch.long).to(device)\n",
        "            v_j = emb(lookup_tensor_j)\n",
        "            word_distance.append((vocabulary[j], float(pdist(v_i, v_j))))\n",
        "            word_distance.sort(key=lambda x: x[1])\n",
        "    return word_distance[:topn]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hotel"
      ],
      "metadata": {
        "id": "u09EfV99Jr_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CBOW2"
      ],
      "metadata": {
        "id": "3uE1YtnEGmbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# word frequency\n",
        "word_freq_hotel = FreqDist(words_hotel)"
      ],
      "metadata": {
        "id": "uhDULsNSt6KH"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort by frequency\n",
        "sorted_keys_hotel = sorted(word_freq_hotel.keys(), key = lambda x : word_freq_hotel[x], reverse = True)"
      ],
      "metadata": {
        "id": "kLLk184Xval8"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_freq_hotel.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nxko129uDeX",
        "outputId": "b170ea22-647d-4e7c-c298-d768f6d51f54"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('hotel', 26584),\n",
              " ('room', 23165),\n",
              " ('stay', 13991),\n",
              " ('great', 10501),\n",
              " ('n', 9323),\n",
              " ('good', 8687),\n",
              " ('staff', 8203),\n",
              " ('night', 7148),\n",
              " ('day', 6641),\n",
              " ('nice', 6533)]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[(x, word_freq_hotel[x]) for x in sorted_keys_hotel[880:890]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5EBf417yj20",
        "outputId": "65d87a43-9566-454d-c96f-ef5ff128b0ad"
      },
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('slipper', 105),\n",
              " ('rip', 105),\n",
              " ('period', 105),\n",
              " ('barrier', 105),\n",
              " ('known', 105),\n",
              " ('neat', 105),\n",
              " ('approach', 105),\n",
              " ('plug', 105),\n",
              " ('calm', 104),\n",
              " ('cramp', 104)]"
            ]
          },
          "metadata": {},
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "4Pdk6klirJYX"
      },
      "outputs": [],
      "source": [
        "chosen_words_hotel = ['hotel', 'staff', 'statement', 'eat', 'jump', 'weigh', 'good', 'nice', 'calm']\n",
        "s = f\"Chosen words:   \\n\\\n",
        "    nouns:  'hotel': {word_freq_hotel['hotel']}, \\n\\\n",
        "            'staff': {word_freq_hotel['staff']}, \\n\\\n",
        "            'statement': {word_freq_hotel['statement']},\\n\\\n",
        "    verbs:  'eat': {word_freq_hotel['eat']}, \\n\\\n",
        "            'jump': {word_freq_hotel['jump']},\\n\\\n",
        "            'weigh': {word_freq_hotel['weigh']},\\n\\\n",
        "    adjs:   'good': {word_freq_hotel['good']}, \\n\\\n",
        "            'nice': {word_freq_hotel['nice']},\\n\\\n",
        "            'calm': {word_freq_hotel['calm']},\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQfVa_U8rJYX",
        "outputId": "826295ff-806c-40a7-a3bd-de60b2806547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen words:   \n",
            "    nouns:  'hotel': 26584, \n",
            "            'staff': 8203, \n",
            "            'statement': 21,\n",
            "    verbs:  'eat': 1594, \n",
            "            'jump': 106,\n",
            "            'weigh': 16,\n",
            "    adjs:   'good': 8687, \n",
            "            'nice': 6533,\n",
            "            'calm': 104,\n"
          ]
        }
      ],
      "source": [
        "print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "fAdIfVjirJYX"
      },
      "outputs": [],
      "source": [
        "chosen_words_neighbors_hotel = [get_closest_word(w, CBOW2_hotel_model, word_to_ix_hotel, vocab_hotel) for w in chosen_words_hotel]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xljb6bzUrJYX",
        "outputId": "15b6a469-0979-4c85-be39-9b42b9153cb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hotel:[('impress', 5.191305160522461), ('room', 5.312654972076416), ('place', 5.365931510925293), ('quit', 5.450966835021973), ('time', 5.5018205642700195)]\n",
            "staff:[('way', 6.993133544921875), ('ruin', 7.030202865600586), ('eye', 7.045656204223633), ('wow', 7.053786277770996), ('threw', 7.065330505371094)]\n",
            "statement:[('gon', 6.269299030303955), ('motor', 6.735846519470215), ('jean', 7.025935173034668), ('pedestrian', 7.571342468261719), ('oven', 7.595150470733643)]\n",
            "eat:[('sign', 6.66425895690918), ('recommend', 7.06675386428833), ('breath', 7.135968208312988), ('studio', 7.2372236251831055), ('run', 7.262462139129639)]\n",
            "jump:[('cross', 6.364423751831055), ('slot', 6.530276298522949), ('dart', 6.550929069519043), ('sent', 6.554869651794434), ('teen', 6.569332599639893)]\n",
            "weigh:[('whirlpool', 6.831803321838379), ('bite', 7.150975704193115), ('shot', 7.3557281494140625), ('bland', 7.364491939544678), ('swimsuit', 7.547054290771484)]\n",
            "good:[('great', 3.9591073989868164), ('excel', 5.080387115478516), ('quit', 5.591042518615723), ('fine', 5.603939056396484), ('best', 5.64713191986084)]\n",
            "nice:[('great', 4.763463497161865), ('excel', 5.397145748138428), ('quit', 5.459486961364746), ('love', 5.699390411376953), ('good', 5.788321018218994)]\n",
            "calm:[('coconut', 6.62074613571167), ('wont', 6.893611907958984), ('deep', 7.01613712310791), ('regular', 7.170494079589844), ('w', 7.191863536834717)]\n"
          ]
        }
      ],
      "source": [
        "for i, w in enumerate(chosen_words_hotel):\n",
        "    print(f\"{w}:{chosen_words_neighbors_hotel[i]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CBOW5"
      ],
      "metadata": {
        "id": "TwcjCbZ1GslU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "K17ieFBIGuyU"
      },
      "outputs": [],
      "source": [
        "chosen_words_neighbors_hotel_5 = [get_closest_word(w, CBOW5_hotel_model, word_to_ix_hotel, vocab_hotel) for w in chosen_words_hotel]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a07fea15-33e3-4502-aa52-8910a28025b4",
        "id": "q4o6DSdhGuyU"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hotel:[('spring', 5.974390983581543), ('grant', 6.408576965332031), ('invest', 6.439939022064209), ('concert', 6.478260040283203), ('card', 6.489580154418945)]\n",
            "staff:[('coconut', 5.714028358459473), ('palm', 5.7422566413879395), ('land', 6.039821624755859), ('housekeep', 6.172938823699951), ('face', 6.232258319854736)]\n",
            "statement:[('pour', 7.124289512634277), ('al', 7.1709442138671875), ('nonetheless', 7.262602806091309), ('towel', 7.268130779266357), ('n', 7.268770217895508)]\n",
            "eat:[('spring', 6.313792705535889), ('palm', 6.437282562255859), ('overbook', 6.4566826820373535), ('facial', 6.485250473022461), ('depress', 6.498972415924072)]\n",
            "jump:[('coconut', 7.1404547691345215), ('fever', 7.264527797698975), ('hectic', 7.315446853637695), ('wo', 7.407448768615723), ('supper', 7.47681999206543)]\n",
            "weigh:[('freeway', 6.294049263000488), ('nit', 6.451268196105957), ('depress', 6.636817455291748), ('lagoon', 6.64177942276001), ('els', 6.867648601531982)]\n",
            "good:[('import', 6.512632369995117), ('partial', 6.529787540435791), ('gon', 6.592710018157959), ('oyster', 6.596374988555908), ('facial', 6.650457859039307)]\n",
            "nice:[('door', 6.14080286026001), ('appoint', 6.52692985534668), ('concert', 6.63807487487793), ('wrong', 6.662891864776611), ('partial', 6.668058395385742)]\n",
            "calm:[('builder', 7.0209126472473145), ('grant', 7.184700012207031), ('cupboard', 7.351058483123779), ('score', 7.361016273498535), ('fell', 7.481769561767578)]\n"
          ]
        }
      ],
      "source": [
        "for i, w in enumerate(chosen_words_hotel):\n",
        "    print(f\"{w}:{chosen_words_neighbors_hotel_5[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, w in enumerate(chosen_words_hotel):\n",
        "    print(f\"{w}:{[x[0] for x in chosen_words_neighbors_hotel_5[i]]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZApmI9wKimg",
        "outputId": "b30c9dda-e9a4-43a6-ece1-c14e1f58c915"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hotel:['spring', 'grant', 'invest', 'concert', 'card']\n",
            "staff:['coconut', 'palm', 'land', 'housekeep', 'face']\n",
            "statement:['pour', 'al', 'nonetheless', 'towel', 'n']\n",
            "eat:['spring', 'palm', 'overbook', 'facial', 'depress']\n",
            "jump:['coconut', 'fever', 'hectic', 'wo', 'supper']\n",
            "weigh:['freeway', 'nit', 'depress', 'lagoon', 'els']\n",
            "good:['import', 'partial', 'gon', 'oyster', 'facial']\n",
            "nice:['door', 'appoint', 'concert', 'wrong', 'partial']\n",
            "calm:['builder', 'grant', 'cupboard', 'score', 'fell']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "st = \"\"\"hotel:['spring', 'grant', 'invest', 'concert', 'card']\n",
        "staff:['coconut', 'palm', 'land', 'housekeep', 'face']\n",
        "statement:['pour', 'al', 'nonetheless', 'towel', 'n']\n",
        "eat:['spring', 'palm', 'overbook', 'facial', 'depress']\n",
        "jump:['coconut', 'fever', 'hectic', 'wo', 'supper']\n",
        "weigh:['freeway', 'nit', 'depress', 'lagoon', 'els']\n",
        "good:['import', 'partial', 'gon', 'oyster', 'facial']\n",
        "nice:['door', 'appoint', 'concert', 'wrong', 'partial']\n",
        "calm:['builder', 'grant', 'cupboard', 'score', 'fell']\"\"\"\n",
        "st = st.replace('[', '')\n",
        "st = st.replace(']', '')\n",
        "print(st)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXPLGJQGLHWH",
        "outputId": "1e838815-ef66-40d8-c3e6-bf909b9777e0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hotel:'spring', 'grant', 'invest', 'concert', 'card'\n",
            "staff:'coconut', 'palm', 'land', 'housekeep', 'face'\n",
            "statement:'pour', 'al', 'nonetheless', 'towel', 'n'\n",
            "eat:'spring', 'palm', 'overbook', 'facial', 'depress'\n",
            "jump:'coconut', 'fever', 'hectic', 'wo', 'supper'\n",
            "weigh:'freeway', 'nit', 'depress', 'lagoon', 'els'\n",
            "good:'import', 'partial', 'gon', 'oyster', 'facial'\n",
            "nice:'door', 'appoint', 'concert', 'wrong', 'partial'\n",
            "calm:'builder', 'grant', 'cupboard', 'score', 'fell'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scifi"
      ],
      "metadata": {
        "id": "E35FrE7LJnri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# word frequency\n",
        "word_freq_scifi = FreqDist(words_scifi)"
      ],
      "metadata": {
        "id": "nWSnpSiUJpqY"
      },
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort by frequency\n",
        "sorted_keys_scifi = sorted(word_freq_scifi.keys(), key = lambda x : word_freq_scifi[x], reverse = True)"
      ],
      "metadata": {
        "id": "fRnB9HHsJ5wt"
      },
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_freq_scifi.most_common(40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUzxOU7dJ9sD",
        "outputId": "0350cbd3-8a80-4f83-81d5-0c8e4f399d3b"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('said', 36714),\n",
              " ('one', 29690),\n",
              " ('would', 22545),\n",
              " ('could', 20325),\n",
              " ('like', 20157),\n",
              " ('look', 18611),\n",
              " ('time', 18051),\n",
              " ('back', 17022),\n",
              " ('go', 16137),\n",
              " ('man', 15834),\n",
              " ('know', 15684),\n",
              " ('get', 14976),\n",
              " ('see', 11592),\n",
              " ('two', 11542),\n",
              " ('way', 11287),\n",
              " ('come', 10938),\n",
              " ('even', 10906),\n",
              " ('thing', 10732),\n",
              " ('hand', 10632),\n",
              " ('think', 10442),\n",
              " ('eye', 10264),\n",
              " ('us', 10019),\n",
              " ('right', 9851),\n",
              " ('want', 9803),\n",
              " ('make', 9770),\n",
              " ('first', 9452),\n",
              " ('thought', 9387),\n",
              " ('well', 9305),\n",
              " ('got', 9065),\n",
              " ('turn', 9055),\n",
              " ('ship', 8655),\n",
              " ('take', 8556),\n",
              " ('littl', 8552),\n",
              " ('long', 8505),\n",
              " ('face', 8496),\n",
              " ('still', 8323),\n",
              " ('around', 8292),\n",
              " ('came', 8218),\n",
              " ('year', 8204),\n",
              " ('someth', 8132)]"
            ]
          },
          "metadata": {},
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[(x, word_freq_scifi[x]) for x in sorted_keys_scifi[2280:2330]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP3SL-joKAb1",
        "outputId": "0e9b5d61-5f15-4cc0-f342-6269d6c442e7"
      },
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ach', 289),\n",
              " ('angel', 289),\n",
              " ('cautious', 289),\n",
              " ('clerk', 289),\n",
              " ('pole', 289),\n",
              " ('reliev', 289),\n",
              " ('log', 289),\n",
              " ('expand', 288),\n",
              " ('shade', 288),\n",
              " ('sensit', 288),\n",
              " ('hut', 288),\n",
              " ('nervous', 288),\n",
              " ('initi', 288),\n",
              " ('inquir', 288),\n",
              " ('spoken', 287),\n",
              " ('estim', 287),\n",
              " ('throughout', 287),\n",
              " ('respond', 286),\n",
              " ('seed', 286),\n",
              " ('tightli', 286),\n",
              " ('snort', 286),\n",
              " ('etern', 286),\n",
              " ('cycl', 286),\n",
              " ('super', 286),\n",
              " ('deeper', 285),\n",
              " ('waist', 285),\n",
              " ('dave', 285),\n",
              " ('react', 285),\n",
              " ('gree', 285),\n",
              " ('bedroom', 284),\n",
              " ('neighbor', 284),\n",
              " ('hollow', 284),\n",
              " ('eric', 284),\n",
              " ('boardman', 284),\n",
              " ('gadget', 283),\n",
              " ('leather', 283),\n",
              " ('drum', 283),\n",
              " ('suspici', 283),\n",
              " ('specul', 283),\n",
              " ('booth', 283),\n",
              " ('blew', 283),\n",
              " ('scarc', 283),\n",
              " ('clip', 283),\n",
              " ('volunt', 283),\n",
              " ('reef', 283),\n",
              " ('packag', 282),\n",
              " ('chill', 282),\n",
              " ('tune', 282),\n",
              " ('stronger', 282),\n",
              " ('heap', 282)]"
            ]
          },
          "metadata": {},
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chosen_words_scifi = ['year', 'bedroom', 'way', 'eat', 'think', 'look', 'good', 'super', 'long']\n",
        "print(\"Chosen words: \\n\")\n",
        "for word in chosen_words_scifi:\n",
        "  print(\"{}: {}\".format(word, word_freq_scifi[word]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-FL-olFKC7G",
        "outputId": "b8e79a78-b29a-4d46-de3b-44985d230b41"
      },
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen words: \n",
            "\n",
            "year: 8204\n",
            "bedroom: 284\n",
            "way: 11287\n",
            "eat: 1193\n",
            "think: 10442\n",
            "look: 18611\n",
            "good: 8129\n",
            "super: 286\n",
            "long: 8505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chosen_words_neighbors_scifi = [get_closest_word(w, CBOW2_scifi_model, word_to_ix_scifi, vocab_scifi) for w in chosen_words_scifi]"
      ],
      "metadata": {
        "id": "gfacAaLoKYuW"
      },
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, w in enumerate(chosen_words_scifi):\n",
        "    print(f\"{w}:{chosen_words_neighbors_scifi[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5KC6KyZKaj_",
        "outputId": "5918b88d-3bbf-4222-8148-e3d5ddfb0a0c"
      },
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "year:[('extract', 7.5398712158203125), ('scan', 7.825392723083496), ('allallu', 7.936631202697754), ('day', 8.008155822753906), ('entic', 8.28494644165039)]\n",
            "bedroom:[('deaden', 5.900077819824219), ('instead', 6.141233444213867), ('cari', 6.186210632324219), ('rhythm', 6.204065322875977), ('musingli', 6.223509311676025)]\n",
            "way:[('think', 4.8308587074279785), ('hing', 5.207362651824951), ('alway', 5.374516487121582), ('mean', 5.477041721343994), ('want', 5.497170448303223)]\n",
            "eat:[('modern', 6.836548328399658), ('opportun', 6.878442764282227), ('thought', 6.9683661460876465), ('nausea', 6.972916126251221), ('tang', 7.009042739868164)]\n",
            "think:[('know', 3.3312723636627197), ('sure', 4.284049034118652), ('find', 4.642031192779541), ('better', 4.791561603546143), ('want', 4.7957682609558105)]\n",
            "look:[('stare', 5.401568412780762), ('turn', 5.785499572753906), ('think', 5.978990077972412), ('flew', 5.981897354125977), ('mightier', 6.16929292678833)]\n",
            "good:[('fixtur', 6.120141983032227), ('desert', 6.437231540679932), ('hope', 6.545134544372559), ('well', 6.555859565734863), ('sure', 6.563302040100098)]\n",
            "super:[('shith', 7.461611747741699), ('thirtieth', 7.466686248779297), ('thish', 7.469206809997559), ('titl', 7.648082256317139), ('openli', 7.650824546813965)]\n",
            "long:[('cascad', 6.728033065795898), ('elfor', 6.876222610473633), ('pwf', 6.950249195098877), ('first', 6.952447414398193), ('fetzer', 6.958423137664795)]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}